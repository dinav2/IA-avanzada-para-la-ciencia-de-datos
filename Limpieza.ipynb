{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dinav2/IA-avanzada-para-la-ciencia-de-datos/blob/main/Limpieza.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAsfkCXtUN_7"
      },
      "source": [
        "## Importar Librerías"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-vgG402rRzSx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from imblearn.combine import SMOTETomek\n",
        "from collections import Counter\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4gbc8u6Yjdo"
      },
      "source": [
        "Funciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xMoV-tHTYwpa"
      },
      "outputs": [],
      "source": [
        "def agrupar_categorias(df, threshold=0.01):\n",
        "    cat_cols = df.select_dtypes(include=['object', 'category']).columns\n",
        "    for col in cat_cols:\n",
        "        freqs = df[col].value_counts(normalize=True)\n",
        "        rare_cats = freqs[freqs < threshold].index\n",
        "        df[col] = df[col].apply(lambda x: 'otras' if x in rare_cats else x)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "EoVGyFTGYi_j"
      },
      "outputs": [],
      "source": [
        "def one_hot_encode(df):\n",
        "    cat_cols = df.select_dtypes(include=['object', 'category']).columns\n",
        "    encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
        "    encoded = encoder.fit_transform(df[cat_cols])\n",
        "    encoded_df = pd.DataFrame(encoded, columns=encoder.get_feature_names_out(cat_cols), index=df.index)\n",
        "    df = df.drop(columns=cat_cols)\n",
        "    df = pd.concat([df, encoded_df], axis=1)\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XirLokBUITF"
      },
      "source": [
        "## Leer Datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2fjqp8UpT40U"
      },
      "outputs": [],
      "source": [
        "base = pd.read_csv('data/Base.csv')\n",
        "variantI = pd.read_csv('data/Variant I.csv')\n",
        "variantII = pd.read_csv('data/Variant II.csv')\n",
        "variantIII = pd.read_csv('data/Variant III.csv')\n",
        "variantIV = pd.read_csv('data/Variant IV.csv')\n",
        "variantV = pd.read_csv('data/Variant V.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTp_NqvjUS7q"
      },
      "source": [
        "## Eliminar Duplicados y Nulos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "LRY-g2V0UV9m"
      },
      "outputs": [],
      "source": [
        "base = base.drop_duplicates().dropna()\n",
        "variantI = variantI.drop_duplicates().dropna()\n",
        "variantII = variantII.drop_duplicates().dropna()\n",
        "variantIII = variantIII.drop_duplicates().dropna()\n",
        "variantIV = variantIV.drop_duplicates().dropna()\n",
        "variantV = variantV.drop_duplicates().dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Lista de columnas a evaluar\n",
        "cols = [\n",
        "    \"prev_address_months_count\",\n",
        "    \"current_address_months_count\",\n",
        "    \"intended_balcon_amount\",\n",
        "    \"bank_months_count\",\n",
        "    \"session_length_in_minutes\",\n",
        "    \"device_distinct_emails_8w\"\n",
        "]\n",
        "\n",
        "def handle_missing_with_fraud(df, cols):\n",
        "    missing_counts = {}\n",
        "\n",
        "    for col in cols:\n",
        "        if col == \"intended_balcon_amount\":\n",
        "            missing_mask = df[col] < 0\n",
        "        else:\n",
        "            missing_mask = df[col] == -1\n",
        "\n",
        "        missing_counts[col] = missing_mask.sum()\n",
        "\n",
        "        if (missing_mask.sum() / len(df)) > 0.5:\n",
        "            df = df.drop(columns=[col])\n",
        "            continue\n",
        "        df = df.drop(df.loc[missing_mask & (df[\"fraud_bool\"] == 0)].index)\n",
        "\n",
        "        valid_values = df.loc[~missing_mask, col]\n",
        "        if not valid_values.empty:\n",
        "            median_val = valid_values.median()\n",
        "            df.loc[missing_mask & (df[\"fraud_bool\"] == 1), col] = median_val\n",
        "\n",
        "\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "base = handle_missing_with_fraud(base, cols)\n",
        "variantI = handle_missing_with_fraud(variantI, cols)\n",
        "variantII = handle_missing_with_fraud(variantII, cols)\n",
        "variantIII = handle_missing_with_fraud(variantIII, cols)\n",
        "variantIV = handle_missing_with_fraud(variantIV, cols)\n",
        "variantV = handle_missing_with_fraud(variantV, cols)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Agrupar Categorías con pocos valores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "HovhKN1iXaDE"
      },
      "outputs": [],
      "source": [
        "base = agrupar_categorias(base)\n",
        "variantI = agrupar_categorias(variantI)\n",
        "variantII = agrupar_categorias(variantII)\n",
        "variantIII = agrupar_categorias(variantIII)\n",
        "variantIV = agrupar_categorias(variantIV)\n",
        "variantV = agrupar_categorias(variantV)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Normalizar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "binary_cols = [\n",
        "    \"fraud_bool\", \"phone_home_valid\", \"phone_mobile_valid\",\n",
        "    \"has_other_cards\", \"foreign_request\", \"keep_alive_session\", \"email_is_free\", \"month\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Normalizar cada dataframe (solo columnas numéricas)\n",
        "num_cols = base.select_dtypes(include=np.number).columns.difference(binary_cols)\n",
        "scaler = StandardScaler()\n",
        "base[num_cols] = scaler.fit_transform(base[num_cols])\n",
        "\n",
        "num_cols = variantI.select_dtypes(include=np.number).columns.difference(binary_cols)\n",
        "scaler = StandardScaler()\n",
        "variantI[num_cols] = scaler.fit_transform(variantI[num_cols])\n",
        "\n",
        "num_cols = variantII.select_dtypes(include=np.number).columns.difference(binary_cols)\n",
        "scaler = StandardScaler()\n",
        "variantII[num_cols] = scaler.fit_transform(variantII[num_cols])\n",
        "\n",
        "num_cols = variantIII.select_dtypes(include=np.number).columns.difference(binary_cols)\n",
        "scaler = StandardScaler()\n",
        "variantIII[num_cols] = scaler.fit_transform(variantIII[num_cols])\n",
        "\n",
        "num_cols = variantIV.select_dtypes(include=np.number).columns.difference(binary_cols)\n",
        "scaler = StandardScaler()\n",
        "variantIV[num_cols] = scaler.fit_transform(variantIV[num_cols])\n",
        "\n",
        "num_cols = variantV.select_dtypes(include=np.number).columns.difference(binary_cols)\n",
        "scaler = StandardScaler()\n",
        "variantV[num_cols] = scaler.fit_transform(variantV[num_cols])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXRxa0EgV5eY"
      },
      "source": [
        "One Hot encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "bs02CVARXirn"
      },
      "outputs": [],
      "source": [
        "base = one_hot_encode(base)\n",
        "variantI = one_hot_encode(variantI)\n",
        "variantII = one_hot_encode(variantII)\n",
        "variantIII = one_hot_encode(variantIII)\n",
        "variantIV = one_hot_encode(variantIV)\n",
        "variantV = one_hot_encode(variantV)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Aplicar SMOTE-Tomek  (Oversample y Undersample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def split_and_balance(\n",
        "    df, \n",
        "    target_col=\"fraud_bool\", \n",
        "    test_size=0.3, \n",
        "    random_state=42, \n",
        "    save_train=\"train_balanced.csv\",\n",
        "    save_test_X=\"X_test.csv\",\n",
        "    save_test_y=\"y_test.csv\",\n",
        "    k_neighbors=2\n",
        "):\n",
        "    \"\"\"\n",
        "    Divide el dataset en train/test, balancea el train con SMOTE-Tomek,\n",
        "    y guarda los resultados en CSV.\n",
        "    \"\"\"\n",
        "    # Separar features y target\n",
        "    X = df.drop(columns=[target_col])\n",
        "    y = df[target_col]\n",
        "\n",
        "    # Train/Test split estratificado\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=test_size, random_state=random_state, stratify=y\n",
        "    )\n",
        "\n",
        "    print(\"Distribución original en train:\\n\", y_train.value_counts())\n",
        "    print(\"Distribución original en test:\\n\", y_test.value_counts())\n",
        "\n",
        "    # Definir SMOTE con sampling_strategy = 0.2\n",
        "    smote = SMOTE(\n",
        "        random_state=random_state, \n",
        "        k_neighbors=k_neighbors, \n",
        "        sampling_strategy=0.2  # minoritaria = 20% de la mayoritaria\n",
        "    )\n",
        "\n",
        "    # Balanceo con SMOTE-Tomek\n",
        "    smote_tomek = SMOTETomek(\n",
        "        random_state=random_state, \n",
        "        smote=smote, \n",
        "        n_jobs=-1\n",
        "    )\n",
        "    X_train_bal, y_train_bal = smote_tomek.fit_resample(X_train, y_train)\n",
        "\n",
        "    # Crear DataFrame balanceado\n",
        "    df_train_bal = pd.DataFrame(X_train_bal, columns=X_train.columns)\n",
        "    df_train_bal[target_col] = y_train_bal\n",
        "\n",
        "    # Guardar datasets\n",
        "    df_train_bal.to_csv(save_train, index=False)\n",
        "    pd.DataFrame(X_test, columns=X_test.columns).to_csv(save_test_X, index=False)\n",
        "    pd.DataFrame(y_test, columns=[target_col]).to_csv(save_test_y, index=False)\n",
        "\n",
        "    print(f\"\\n Train balanceado (20%) guardado en '{save_train}'\")\n",
        "    print(f\" X_test guardado en '{save_test_X}'\")\n",
        "    print(f\" y_test guardado en '{save_test_y}'\")\n",
        "\n",
        "    return df_train_bal, X_test, y_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Split and balance base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# df_train_bal, X_test, y_test = split_and_balance(base, target_col=\"fraud_bool\", save_train=\"train_balanced_base.csv\", save_test_X=\"X_test_base.csv\", save_test_y=\"y_test_base.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Filtrar el dataframe base para incluir solo filas donde 'month' está entre 0 y 5\n",
        "#base_months_0_5 = base[base['month'].between(0, 5)]\n",
        "\n",
        "# Ahora puedes hacer el split y balanceo solo con estos datos\n",
        "#df_train_bal_months_0_5, X_test_months_0_5, y_test_months_0_5 = split_and_balance(\n",
        "    #base_months_0_5,\n",
        "    #target_col=\"fraud_bool\",\n",
        "    #save_train=\"train_balanced_base_months_0_5.csv\",\n",
        "   # save_test_X=\"X_test_base_months_0_5.csv\",\n",
        "    #save_test_y=\"y_test_base_months_0_5.csv\"\n",
        "#)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Combinar Base, VariantI y VariantII"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'base' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Filtrar por meses 0-5\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m base_months_0_5 = \u001b[43mbase\u001b[49m[base[\u001b[33m'\u001b[39m\u001b[33mmonth\u001b[39m\u001b[33m'\u001b[39m].between(\u001b[32m0\u001b[39m, \u001b[32m5\u001b[39m)]\n\u001b[32m      3\u001b[39m variantI_months_0_5 = variantI[variantI[\u001b[33m'\u001b[39m\u001b[33mmonth\u001b[39m\u001b[33m'\u001b[39m].between(\u001b[32m0\u001b[39m, \u001b[32m5\u001b[39m)]\n\u001b[32m      4\u001b[39m variantII_months_0_5 = variantII[variantII[\u001b[33m'\u001b[39m\u001b[33mmonth\u001b[39m\u001b[33m'\u001b[39m].between(\u001b[32m0\u001b[39m, \u001b[32m5\u001b[39m)]\n",
            "\u001b[31mNameError\u001b[39m: name 'base' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "# Filtrar por meses 0-5\n",
        "base_months_0_5 = base[base['month'].between(0, 5)]\n",
        "variantI_months_0_5 = variantI[variantI['month'].between(0, 5)]\n",
        "variantII_months_0_5 = variantII[variantII['month'].between(0, 5)]\n",
        "\n",
        "# Tomar 80% de base, 30% de variantI y 30% de variantII\n",
        "base_months_0_5 = base_months_0_5.sample(frac=0.8, random_state=42)\n",
        "variantI_months_0_5 = variantI_months_0_5.sample(frac=0.3, random_state=42)\n",
        "variantII_months_0_5 = variantII_months_0_5.sample(frac=0.3, random_state=42)\n",
        "\n",
        "\n",
        "# Combine them\n",
        "combined_months_0_5 = pd.concat([base_months_0_5, variantI_months_0_5, variantII_months_0_5], ignore_index=True)\n",
        "print(combined_months_0_5.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distribución original en train:\n",
            " fraud_bool\n",
            "0    577505\n",
            "1      7996\n",
            "Name: count, dtype: int64\n",
            "Distribución original en test:\n",
            " fraud_bool\n",
            "0    247503\n",
            "1      3427\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Ahora puedes hacer el split y balanceo solo con estos datos\n",
        "df_train_bal_com_months_0_5, X_test_com_months_0_5, y_test_com_months_0_5 = split_and_balance(\n",
        "    combined_months_0_5,\n",
        "    target_col=\"fraud_bool\",\n",
        "    save_train=\"train_balanced_combined_months_0_5.csv\",\n",
        "    save_test_X=\"X_test_combined_months_0_5.csv\",\n",
        "    save_test_y=\"y_test_combined_months_0_5.csv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#base_balanced = pd.read_csv('train_balanced_combined.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1446004, 45)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#base_balanced.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "fraud_bool\n",
              "0    723002\n",
              "1    723002\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#base_balanced[\"fraud_bool\"].value_counts()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMDwgo8iEf7UWcOxLQ2xGbK",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv (3.11.4)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
