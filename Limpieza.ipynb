{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dinav2/IA-avanzada-para-la-ciencia-de-datos/blob/main/Limpieza.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAsfkCXtUN_7"
      },
      "source": [
        "## Importar Librerías"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "-vgG402rRzSx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4gbc8u6Yjdo"
      },
      "source": [
        "Funciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "xMoV-tHTYwpa"
      },
      "outputs": [],
      "source": [
        "def agrupar_categorias(df, threshold=0.01):\n",
        "    cat_cols = df.select_dtypes(include=['object', 'category']).columns\n",
        "    for col in cat_cols:\n",
        "        freqs = df[col].value_counts(normalize=True)\n",
        "        rare_cats = freqs[freqs < threshold].index\n",
        "        df[col] = df[col].apply(lambda x: 'otras' if x in rare_cats else x)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "EoVGyFTGYi_j"
      },
      "outputs": [],
      "source": [
        "def one_hot_encode(df):\n",
        "    cat_cols = df.select_dtypes(include=['object', 'category']).columns\n",
        "    encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
        "    encoded = encoder.fit_transform(df[cat_cols])\n",
        "    encoded_df = pd.DataFrame(encoded, columns=encoder.get_feature_names_out(cat_cols), index=df.index)\n",
        "    df = df.drop(columns=cat_cols)\n",
        "    df = pd.concat([df, encoded_df], axis=1)\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def remove_outliers(df):\n",
        "    num_cols = df.select_dtypes(include=np.number).columns\n",
        "    for col in num_cols:\n",
        "        Q1 = df[col].quantile(0.25)\n",
        "        Q3 = df[col].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        mask = (df[col] >= Q1 - 1.5 * IQR) & (df[col] <= Q3 + 1.5 * IQR)\n",
        "        df = df[mask]\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XirLokBUITF"
      },
      "source": [
        "## Leer Datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2fjqp8UpT40U"
      },
      "outputs": [],
      "source": [
        "base = pd.read_csv('/content/Base.csv')\n",
        "variantI = pd.read_csv('/content/Variant I.csv')\n",
        "variantII = pd.read_csv('/content/Variant II.csv')\n",
        "variantIII = pd.read_csv('/content/Variant III.csv')\n",
        "variantIV = pd.read_csv('/content/Variant IV.csv')\n",
        "variantV = pd.read_csv('/content/Variant V.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTp_NqvjUS7q"
      },
      "source": [
        "## Eliminar Duplicados y Nulos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LRY-g2V0UV9m"
      },
      "outputs": [],
      "source": [
        "base = base.drop_duplicates().dropna()\n",
        "variantI = variantI.drop_duplicates().dropna()\n",
        "variantII = variantII.drop_duplicates().dropna()\n",
        "variantIII = variantIII.drop_duplicates().dropna()\n",
        "variantIV = variantIV.drop_duplicates().dropna()\n",
        "variantV = variantV.drop_duplicates().dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Lista de columnas\n",
        "cols = [\n",
        "    \"prev_address_months_count\",\n",
        "    \"current_address_months_count\",\n",
        "    \"intended_balcon_amount\",\n",
        "    \"bank_months_count\",\n",
        "    \"session_length_in_minutes\",\n",
        "    \"device_distinct_emails_8w\"\n",
        "]\n",
        "\n",
        "# Contamos missing por columna\n",
        "missing_counts = {}\n",
        "for col in cols:\n",
        "    if col == \"intended_balcon_amount\":\n",
        "        missing_counts[col] = (base[col] < 0).sum()\n",
        "    else:\n",
        "        missing_counts[col] = (base[col] == -1).sum()\n",
        "\n",
        "# Convertimos a DataFrame\n",
        "missing_df = pd.DataFrame.from_dict(missing_counts, orient='index', columns=['Missing Values'])\n",
        "print(missing_df)\n",
        "\n",
        "# Total de missing en todo el dataset\n",
        "print(\"\\nTotal missing values en todas las columnas:\", missing_df['Missing Values'].sum())\n",
        "\n",
        "# --- Visualización ---\n",
        "missing_df.plot(kind='bar', legend=False, figsize=(8,4), color='tomato')\n",
        "plt.title(\"Missing values por columna\")\n",
        "plt.ylabel(\"Cantidad\")\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "missing_counts = {}\n",
        "for col in cols:\n",
        "    if col == \"intended_balcon_amount\":\n",
        "        missing_counts[col] = (variantI[col] < 0).sum()\n",
        "    else:\n",
        "        missing_counts[col] = (variantI[col] == -1).sum()\n",
        "\n",
        "# Convertimos a DataFrame\n",
        "missing_df = pd.DataFrame.from_dict(missing_counts, orient='index', columns=['Missing Values'])\n",
        "print(missing_df)\n",
        "\n",
        "# Total de missing en todo el dataset\n",
        "print(\"\\nTotal missing values en todas las columnas:\", missing_df['Missing Values'].sum())\n",
        "\n",
        "# --- Visualización ---\n",
        "missing_df.plot(kind='bar', legend=False, figsize=(8,4), color='tomato')\n",
        "plt.title(\"Missing values por columna\")\n",
        "plt.ylabel(\"Cantidad\")\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Eliminar columnas con muchos datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "base = base.drop(columns=['prev_address_months_count','intended_balcon_amount'])\n",
        "variantI = variantI.drop(columns=['prev_address_months_count','intended_balcon_amount'])\n",
        "variantII = variantII.drop(columns=['prev_address_months_count','intended_balcon_amount'])\n",
        "variantIII = variantIII.drop(columns=['prev_address_months_count','intended_balcon_amount'])\n",
        "variantIV = variantIV.drop(columns=['prev_address_months_count','intended_balcon_amount'])\n",
        "variantV = variantV.drop(columns=['prev_address_months_count','intended_balcon_amount'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "base = remove_outliers(base)\n",
        "variantI = remove_outliers(variantI)\n",
        "variantII = remove_outliers(variantII)\n",
        "variantIII = remove_outliers(variantIII)\n",
        "variantIV = remove_outliers(variantIV)\n",
        "variantV = remove_outliers(variantV)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stIxFpxPVG2l"
      },
      "source": [
        "## Normalizar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_AYsD1XKVWsR"
      },
      "outputs": [],
      "source": [
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "base_num = base.select_dtypes(include=np.number)\n",
        "base[base_num.columns] = scaler.fit_transform(base_num)\n",
        "\n",
        "variantI_num = variantI.select_dtypes(include=np.number)\n",
        "variantI[variantI_num.columns] = scaler.fit_transform(variantI_num)\n",
        "\n",
        "variantII_num = variantII.select_dtypes(include=np.number)\n",
        "variantII[variantII_num.columns] = scaler.fit_transform(variantII_num)\n",
        "\n",
        "variantIII_num = variantIII.select_dtypes(include=np.number)\n",
        "variantIII[variantIII_num.columns] = scaler.fit_transform(variantIII_num)\n",
        "\n",
        "variantIV_num = variantIV.select_dtypes(include=np.number)\n",
        "variantIV[variantIV_num.columns] = scaler.fit_transform(variantIV_num)\n",
        "\n",
        "variantV_num = variantV.select_dtypes(include=np.number)\n",
        "variantV[variantV_num.columns] = scaler.fit_transform(variantV_num)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Agrupar Categorías con pocos valores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "HovhKN1iXaDE"
      },
      "outputs": [],
      "source": [
        "base = agrupar_categorias(base)\n",
        "variantI = agrupar_categorias(variantI)\n",
        "variantII = agrupar_categorias(variantII)\n",
        "variantIII = agrupar_categorias(variantIII)\n",
        "variantIV = agrupar_categorias(variantIV)\n",
        "variantV = agrupar_categorias(variantV)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXRxa0EgV5eY"
      },
      "source": [
        "One Hot encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "bs02CVARXirn"
      },
      "outputs": [],
      "source": [
        "base = one_hot_encode(base)\n",
        "variantI = one_hot_encode(variantI)\n",
        "variantII = one_hot_encode(variantII)\n",
        "variantIII = one_hot_encode(variantIII)\n",
        "variantIV = one_hot_encode(variantIV)\n",
        "variantV = one_hot_encode(variantV)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calcular el porcentaje de fraudes entre los outliers de todas las columnas numéricas usando IQR\n",
        "outlier_fraud_percent = {}\n",
        "for col in base.select_dtypes(include='number').columns:\n",
        "    if col == 'fraud_bool':\n",
        "        continue\n",
        "    Q1 = base[col].quantile(0.25)\n",
        "    Q3 = base[col].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    outliers = base[(base[col] < Q1 - 1.5 * IQR) | (base[col] > Q3 + 1.5 * IQR)]\n",
        "    if len(outliers) > 0:\n",
        "        percent = (outliers['fraud_bool'] == 1).mean() * 100\n",
        "        outlier_fraud_percent[col] = percent\n",
        "    else:\n",
        "        outlier_fraud_percent[col] = None\n",
        "print('Porcentaje de fraudes entre outliers por columna:')\n",
        "for col, pct in outlier_fraud_percent.items():\n",
        "    print(f'{col}: {pct if pct is not None else \"No hay outliers\"}%')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMDwgo8iEf7UWcOxLQ2xGbK",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
